---
title: "Gerson de Kleuver"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    storyboard: true
    theme: flatly
    highlight: monochrome
    css: styles.css
    logo: 'C:\Users\kleuv\Documents\Homework-Week-5-\oopga.png'
  
---

```{r preprocessing, message = FALSE, include=FALSE, cache=TRUE}
library(dplyr)
library(ggplot2)
library(tidyverse)
library(flexdashboard)
library(compmus)
library(spotifyr)
library(plotly)
library(tidymodels)
library(ggdendro)
library(heatmaply)
library(ggpubr)
library(gridExtra)

LP <- get_playlist_audio_features("", "37i9dQZF1DWVi45nh2EuPP")
GP <- get_playlist_audio_features("", "4bx5c78CAquCWNE4tw1reY")
MP <- get_playlist_audio_features("", "5AHH67GYsljwoB1q6UGvWg")
UGP <- get_playlist_audio_features("", "37i9dQZF1DWYN9NBqvY7Tx")


XP <-
  bind_rows(
    LP %>% mutate(playlist = "League of legends playlist"),
    GP %>% mutate(playlist = "Gaming playlist"),
    MP %>% mutate(playlist = "Magic Music EDM Gaming Playlist"),
    UGP %>% mutate(playlist = "Ultra Gaming")
  )

XP013 <-
  bind_rows(
    LP %>% mutate(playlist = "League of legends"),
    GP %>% mutate(playlist = "Gaming"),
    MP %>% mutate(playlist = "Magic Music EDM Gaming"),
    UGP %>% mutate(playlist = "Ultra Gaming")
  )


genre <- c("Rap", "Heavy-Metal", "Alternative Rock", "R&B", "Hip-hop", "Pop", "EDM", "Classic Rock", "Contemporary Rock", "New Age", "Folk", "Adult contemporary", "Classical", "Country", "Oldies", "Raggeton", "Latin", "Smooth Jazz", "Raggae", "Holiday")
index <- c(1.21, 1.20, 1.19, 1.19, 1.13, 1.10, 1.09, 1.08, 1.06, 1.02, 1.01, 0.98, 0.98, 0.97, 0.96, 0.96, 0.95, 0.95, 0.94, 0.93)
df <- data.frame(genre, index)
```

Introduction
============

SideBar {.sidebar}
--------------

#### Gaming data sets:


[Magic Music EDM Gaming Playlist](https://open.spotify.com/playlist/5AHH67GYsljwoB1q6UGvWg?si=01c590f404924c96):

* Songs: 247 

* Likes: 474.991

* By: Magic records

[Gaming playlist](https://open.spotify.com/playlist/4bx5c78CAquCWNE4tw1reY?si=8b1700cc937d4d1d):

* Songs: 98

* Likes: 212.732

* By: Gaming Playlist

[League of Legends Official Playlist](https://open.spotify.com/playlist/37i9dQZF1DWVi45nh2EuPP?si=2829a0729b984f8e):

* Songs: 166

* Likes: 289.577

* By: Spotify

[Ultra Gaming](https://open.spotify.com/playlist/37i9dQZF1DWYN9NBqvY7Tx):

* Songs: 100

* Likes: 22.233

* By: Spotify


```{html}
<object data="https://open.spotify.com/embed/playlist/37i9dQZF1DWVi45nh2EuPP"> width="260" height="260" style="display:block;margin:auto">
  <embed src="https://open.spotify.com/embed/playlist/37i9dQZF1DWVi45nh2EuPP" width="260" height="260"> </embed>
</object>
  
```

Column
--------------
Gaming music is a broad term which describes a group of music that is often related to the playing of watching of video games. It as a category has grown immensely, as music and playlists carrying such label is being uploaded every day in large quantities to youtube and spotify.
  
  A very notible gaming playlist was released by Spotify in 2020, the official League of Legends playlist. This playlist contained big songs made suchs as [Imagine Dragons's 10th most popular track Warriors](https://open.spotify.com/track/1sWeSMifj6Z6kZyI6z3bRc?si=39a6e0d8cd244d30) which was specifically made to promote the League of legends world championship in 2014. However the playlist also contains many lesser known songs and they belong to many different genres. This is fairly typical with gaming playlists as the songs within such playlist range anywhere from indie to darksynth. 
  
  Thus one could ask the question if correlations exist between the tracks within this playlist that make them recognizable as being a gaming track. 
  
  This playlist also contains all songs that were officially published by League of Legends, these "official" tracks are note worthy since some of them use audio of the game. Perhaps these songs have interesting similarities. These songs include:
  
  * [Warriors (2020 version)](https://open.spotify.com/track/3f4fc8c8unrQeKecmUPEDR?si=63276ad4a4564a17)
  
  * [Warriors (2014 version)](https://open.spotify.com/track/1lgN0A2Vki2FTON5PYq42m?si=dd0a95a23d5c48c1)
  
  * [Legends never die](https://open.spotify.com/track/1FpVJ7HpZInE2GvhVE2TwT?si=0ffca8d599cc41d4)
  
  * [RISE](https://open.spotify.com/track/69Sy7207dnixZ6w7RSV9Kb?si=db38cd8a58a8415b)
  
  * [Phoenix](https://open.spotify.com/track/6zAiRKvAMlXHxEtyO4yxIO?si=49498516b2e7491b)
  
  * [Take over](https://open.spotify.com/track/7asFSf2pkWNEG3E5EuN1QR?si=91587d78bc0c4980)
  
  * [Awaken](https://open.spotify.com/track/3jevgr3fYdv9wYO3IDJq2a?si=46970ba4b74843dd)
  
The genres assosiated with gaming music might also be of interest.
  [A study](https://www.billboard.com/articles/business/9423462/gamers-top-20-favorite-music-genres) performed by Nielsen Music surveyed 3757 participants measured how many "gamers" listen to a genre compared to "non gamers" to come up with an index.
  
```{r cache=TRUE}
histostats <- df %>% 
  arrange(index) %>%
  ggplot(aes(x = genre,y=index)) +
  geom_point(size=3) +
  coord_flip() + 
  geom_segment(aes(x=genre, 
                   xend=genre, 
                   y=1, 
                   yend=index)) +
  geom_hline(yintercept=1) +
  ggtitle("Index of genres listend to by gamers") +
  labs(title="Index of genres listend to by gamers") + 
  theme(axis.text.x = element_text(angle=0, vjust=0.6),
  plot.background = element_rect(fill = "transparent"))

ggplotly(histostats)
```
It might be interesing to look between the diffrence of a popular pop song within the league of legends playist and another popular song from another genre.


A question remains, is the playlist representative of gaming music in the first place? Since it contains mostly of electronic dance and indie music. To valdiate any claims in this portifolio 3 additional popular playlists are used to hopefully be able to draw meaningfull comparisons. 2 of these playlists ("EDM Gaming Playlist":474.991 likes and "Gaming playlist": 212.732 likes) are very popular on spotify and are published and composed by spotify users while the other playlist ("Ultra Gaming": 22.229 likes) is much less popular but officially published by spotify. 

Data exploration {.storyboard}
===============
### How acoustic is the League of legends playlist?

``` {r cache=TRUE}
AuPlot <- XP %>%
  ggplot(aes(x = playlist, y = acousticness, fill=playlist)) +
  geom_violin() +
  ggtitle("Acousticness of gaming playlists") + theme(legend.position = "none") +
  theme(plot.background = element_rect(fill = "transparent")) 
ggplotly(AuPlot)
```
***

What is a characteristic feature of a gaming playlist? One of the immediate things that come to mind is the use of electric instruments such as a synthesizer. Songs such as [Maniac](https://open.spotify.com/album/2m7pyAC9xDlLBPjBFqqrNV?highlight=spotify:track:2IxhiriDpu4iBnXZb3ytXN) by Carpenter Brut in the league of legends playlist heavily rely on the use of electronic instruments. Is this common in all gaming playlists? If so is the League of legends playlist an outlier?

---

Spotify has labeled their songs on **Acousticness** with a value ranging from 0 to 1, 0 indicates that a track is not acoustic at all while 1 means it is a fully acoustic track. 

The violin plot on the left shows several things:

* all these playlists constist of mostly non acoustic tracks

* The playlists provided by spotify (Ultra gaming and League of Legends) have even less acousticness

* The league of legends playlist has some outliers, however is mostly non acoustic.

The violin plot makes use of **density** to describe the proportion of tracks on a certain level of Acousticness. It is remarkable that the League of legends playlist is nearly completely non acoustic. 

---

The acousticness from the League of legends playlist seems much lower with most tracks within the 0.007 range.

### How energetic is the League of Legends playlist?
````{r cache=TRUE}
pointPLOT <- XP %>%
  ggplot(aes(x = danceability , fill=playlist,color=playlist,y =valence , alpha=energy)) +
  geom_point(size=2) +
  ggtitle("Correlations between gaming playlists") +
  geom_smooth() +
  theme(plot.background = element_rect(fill = "transparent"))
ggplotly(pointPLOT)
```

***

Another common assumption is that gaming music is generally energetic. How does the League of legends playlist compare?  

---

Spotify provides several audio features which are of interest. **Energy** describes how noicy a track is, **Valence** describes the positiveness  of a song and finally **Danceability** discribes how dancable a song is. All these features range with values between 0 and 1. 

---

Clearly visible is that the gaming songs are all not too positive with the majority of the tracks on all playlists are below a positivity value of 0.5. Another commonality between the playlists is that most tracks are above 0.5 dancablility . The league of legends playlist seems to align with the other playlists in these cases. In energy all these songs are also rather common. 


### What are the difference in playlist features?

```{r cache=TRUE}

XP2 <- XP013 %>%
  ggplot(aes(x=energy, fill=playlist )) +
  geom_histogram(binwidth=0.1, color="black") +
  ylim(0,100) +
  facet_wrap(~ playlist)+
  labs(color='Playlist', title='Energy per Playlist') +
  xlab('Energy') +
  ylab("Count") +
  theme(legend.position = "none")

XP3 <-XP013 %>%
  ggplot(aes(x=tempo, fill=playlist )) +
  geom_histogram(binwidth=30, color="black") +
  ylim(0,150) +
  facet_wrap(~ playlist)+
  labs(color='Playlist', title='Tempo per Playlist') +
  xlab('Tempo') +
  ylab("Count") +
  theme(legend.position = "none")


XP5 <- XP013 %>%
  ggplot(aes(x=instrumentalness, fill=playlist )) +
  geom_histogram(binwidth=0.1, color="black") +
  ylim(0,30) +
  facet_wrap(~ playlist)+
  labs(color='Playlist', title='Instrumentalness per Playlist') +
  xlab('Instumentalness') +
  ylab("Count")+
  theme(legend.position = "none")


XP6 <- XP013 %>%
  ggplot(aes(x=loudness, fill=playlist )) +
  geom_histogram(binwidth=2, color="black") +
  ylim(0,120) +
  facet_wrap(~ playlist)+
  labs(color='Playlist', title='Loudness per Playlist') +
  xlab('Loudness') +
  ylab("Count")+
  theme(legend.position = "none")


ggarrange(XP3,XP5,XP2,XP6)

```

***

If we look at the several different features, we cannot draw too many conclusions. However there are some notible observations:

* The league of legends playlist has a much higher average instrumentalness

* he community playlists seem to both be more energetic, louder and of higher tempo than the playlists published by spotify.


while looking the instrumentalness we can clearly see that the league of legends playlist is an outlier. This is probably becaus of songs such as Warriors 2020. Which was produced with a large orchestra. And are made for both tournament usage and as promototional songs.


### What can we tell from the most popular tracks?
```{r cache=TRUE}
Warriors_2020 <-
  get_tidy_audio_analysis("3f4fc8c8unrQeKecmUPEDR") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

Warriors_2014 <-
  get_tidy_audio_analysis("1sWeSMifj6Z6kZyI6z3bRc") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

Legends_never_die <-
  get_tidy_audio_analysis("1FpVJ7HpZInE2GvhVE2TwT") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

RISE <-
  get_tidy_audio_analysis("69Sy7207dnixZ6w7RSV9Kb") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)




TXP <-
  bind_rows(
    Warriors_2020 %>% mutate(track = "Warriors 2020"),
    Warriors_2014 %>% mutate(track = "Warriors 2014"),
    Legends_never_die %>% mutate(track = "Legends never die 2017"),
    RISE %>% mutate(track = "RISE 2018")
  )

TXP %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c() +
  facet_wrap(~track) + theme(legend.position = "none") + 
  theme(plot.background = element_rect(fill = "transparent"))


```

***

Lets look at League of legends most iconic songs: Rise, Legends never die, and Warriors. Warriors has had 2 releases, the 2014 release and the 2020 cover. Are they similar in sound?

---

Lets take a look at both versions and the other tracks using a **chromagram**. A chromagram visualizes the pitches in a track on a certain time. The values range from 0 to 1, with 0 being an absence from a pitches entirely. The chromagram also gives a insight in the structure of a song, since certain pattern of pitches are being repeated mutliple times. 

---

The chromagrams on the left differ in shapes, this is due to the tracks having different lengths.
An interesting sight is that 3 of the 4 tracks are  in C and C#. All these songs are more directly made by Riot games, the studio behind League of legends. All 3 were made by the companies music studio "penta kill", while the original version of warriors from 2014 made by Imagine Dragons is very much different than its 2020 release. 

Thus perhaps one could say that most recent gaming music has evolved in terms of C and C# usage.


### Structure of Legends never Die

```{r cache=TRUE}
TO <-
  get_tidy_audio_analysis("1FpVJ7HpZInE2GvhVE2TwT") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
b2 <- bind_rows(
  TO %>%
    compmus_self_similarity(pitches, "aitchison") %>%
    mutate(d = d / max(d), type = "Chroma"),
  TO %>%
    compmus_self_similarity(timbre, "euclidean") %>%
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "" ) +
  geom_vline(xintercept=40, colour="white") +
  geom_text(aes(x=40, label="Intro", y=40), colour="white", angle=90,text=element_text(size=11)) +
  geom_vline(xintercept=60, colour="red") +
  geom_text(aes(x=60, label="Chorus", y=20), colour="red", angle=90,text=element_text(size=11)) +
    geom_vline(xintercept=122, colour="red") +
  geom_text(aes(x=122, label="Chorus
", y=20), colour="red", angle=90,text=element_text(size=11))+ 
    geom_vline(xintercept=177, colour="red") +
  geom_text(aes(x=177, label="Chorus
", y=20), colour="red", angle=90,text=element_text(size=11)) +
    geom_vline(xintercept=209, colour="white") +
  geom_text(aes(x=209, label="End
", y=40), colour="white", angle=90,text=element_text(size=11)) +
  theme(plot.background = element_rect(fill = "transparent")) 


TE <-
  get_tidy_audio_analysis("69Sy7207dnixZ6w7RSV9Kb") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
b1 <- bind_rows(
  TE %>%
    compmus_self_similarity(pitches, "aitchison") %>%
    mutate(d = d / max(d), type = "Chroma"),
  TE %>%
    compmus_self_similarity(timbre, "euclidean") %>%
    mutate(d = d / max(d), type = "Timbre")
    
) %>%
  mutate() %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "") +
  geom_vline(xintercept=42, colour="white") +
  geom_text(aes(x=42, label="Intro / Chorus", y=40), colour="white", angle=90,text=element_text(size=11)) +
      geom_vline(xintercept=87, colour="red") +
  geom_text(aes(x=87, label="Chorus
", y=20), colour="red", angle=90,text=element_text(size=11)) +
        geom_vline(xintercept=132, colour="red") +
  geom_text(aes(x=132, label="Chorus
", y=20), colour="red", angle=90,text=element_text(size=11)) + 
  
          geom_vline(xintercept=110, colour="yellow") +
  geom_text(aes(x=110, label="Bridge
", y=40), colour="yellow", angle=90,text=element_text(size=11)) +
  theme(plot.background = element_rect(fill = "transparent")) 

ggarrange(b1, b2)

```

---

The previous Chromagrams were interesting as to indicate how the tone layout looks. However it failed to visualize the structure of the songs effectively. One could expect that even though they seem very different the underlying structure might be similar, since their tone usage is also similar and they were published by the same company. Lets take a look at RISE and Legends never die, to assess their structure.

---

To visualize the structure of a track effectively one could split a track in a visualization of the **chroma** (pitches) and a visualization of the **timbre**.  Timbre is the overall fidelity of sound. 
The most effective way of plotting these is using a **self-similarity plot**. To create one the track is split in sections, then the pitches in a section are compared to all other sections this is done for all sections. If a section is very similar it is assigned a higher value than one which is very similar. One effect that might occur when using self-similarity plots is checker boarding. This highlights repeating patterns or a shift in structure within a track.

---

The structure of Legends never die seems very much deliberatly crafted, with the chorus kicking in about every minute, with the first chorus kicking in at exactly 1 minute. Furthermore the intro of the song ends about 41 seconds in, while the outro starts at about 3:30. These numbers gain meaning when compared to RISE. RISE's intro ends at about 42 seconds in which is almost at the same time as Legends never die, futhermore it also has 3 choruses which are each about 45 seconds apart. These conclusions were drawn on the timbre, Looking at the chroma we can see different patterns such as the bridge at 1:50 in RISE clearly which leads to the final chorus. 

### Chordo gram

####

Lets look at chords, the chords of both versions of Warriors, legends never die, and RISE again. <br>
How good is spotify in detecting the chords and are there some noteworthy characteristics?

---

How do we look at chords? A **chordogram** is the best solution. We can use the chromas to inference which chords are being played.


####

```{r cache=TRUE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )


Legends <-
  get_tidy_audio_analysis("1FpVJ7HpZInE2GvhVE2TwT") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

Legends %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "", title="Legends never die") + 
  geom_vline(xintercept=208, colour="black", size=3) +
  geom_text(aes(x=208, label="Outro
", y=3), colour="black", angle=90,text=element_text(size=11)) +
  theme(plot.background = element_rect(fill = "transparent"))

```

####

```{r cache=TRUE}


RISECG <-
  get_tidy_audio_analysis("69Sy7207dnixZ6w7RSV9Kb") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

RISECG %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "", title="RISE") +
  geom_vline(xintercept=10, colour="black",size=3 ) +
  geom_text(aes(x=10, label="Intro
", y=3), colour="black", angle=90,text=element_text(size=11)) +
  theme(plot.background = element_rect(fill = "transparent"))
```

```{r cache=TRUE}
WARRIORSCG20 <-
  get_tidy_audio_analysis("3f4fc8c8unrQeKecmUPEDR") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )


WARRIORSCG20 %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "",  title="Warriors 2020") +
    geom_vline(xintercept=191, colour="black", size=3) +
  geom_text(aes(x=191, label="Outro
", y=3), colour="black", angle=90,text=element_text(size=11)) +
      geom_vline(xintercept=11, colour="black") +
  geom_text(aes(x=11, label="Intro
", y=3), colour="black", angle=90,text=element_text(size=11)) +
      geom_vline(xintercept=14, colour="white" ) +
  geom_text(aes(x=14, label="Intro by ear
", y=9), colour="white", angle=90,text=element_text(size=11)) +
  theme(plot.background = element_rect(fill = "transparent"))
```

```{r cache=TRUE}
WARRIORSCG14 <-
  get_tidy_audio_analysis("1sWeSMifj6Z6kZyI6z3bRc") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

WARRIORSCG14 %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "", title="Warriors 2014") +
      geom_vline(xintercept=8, colour="black") +
  geom_text(aes(x=8, label="Intro
", y=3), colour="black", angle=90,text=element_text(size=11)) +
      geom_vline(xintercept=6, colour="white" ) +
  geom_text(aes(x=6, label="Intro by ear
", y=9), colour="white", angle=90,text=element_text(size=11)) +
  theme(plot.background = element_rect(fill = "transparent"))
```

***

Notible is that Warriors 2020 the most recent song has a change in chords at the start and end, while RISE had one and the start and Legends never die had one at the end. The chordogram captures them almost perfectly. With RISE being an example where it is perfectly visualized, it detects the start of a drum repetition. However at times the chords seem to differ than can be heard by ear, thus it is not completely accurate. Thought chordograms are all in all suprisingly accurate.




### What can we say about the tempo?

#### Legends never die

```{r cache=TRUE}
Legends_never_die2 <- get_tidy_audio_analysis("1FpVJ7HpZInE2GvhVE2TwT")
LOL2 <- Legends_never_die2 %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic() +
  theme(plot.background = element_rect(fill = "transparent")) +
   geom_hline(yintercept=280, colour="black")


Legends_never_die1 <- get_tidy_audio_analysis("1FpVJ7HpZInE2GvhVE2TwT")
LOL1 <- Legends_never_die1 %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()  +
  geom_hline(yintercept=240, colour="black")

subplot(LOL1, LOL2)

```



#### RISE

```{r cache=TRUE}
RISE2 <- get_tidy_audio_analysis("69Sy7207dnixZ6w7RSV9Kb")
LOL23 <- RISE2 %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic() +
  theme(plot.background = element_rect(fill = "transparent")) 


RISE1 <- get_tidy_audio_analysis("69Sy7207dnixZ6w7RSV9Kb")
LOL13 <- RISE1 %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic() +
  theme(plot.background = element_rect(fill = "transparent")) 

subplot(LOL13, LOL23)

```


*** 




### What can we say about tempo between playlists?

####

Now lets look at de tempo on a playlist scale. How much do the playlist differ from eachtoher and for example an electronics playlist. 


####

```{r cache=TRUE}
MP2 <-
  get_playlist_audio_features("",
    "5AHH67GYsljwoB1q6UGvWg"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
UGP2 <-
  get_playlist_audio_features("",
    "37i9dQZF1DWYN9NBqvY7Tx"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
GP2 <-
  get_playlist_audio_features("",
    "2cjIvuw4VVOQSeUAZfNiqY"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
asP2 <-
  get_playlist_audio_features("",
    "1vXfh0fQrN5YQlhFVS6ec5"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
hip <-
  get_playlist_audio_features("",
    "4fAWoOyXtEjLn9PT2RLyzO"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
```

####

```{r cache=TRUE}

jazz3131 <-
  bind_rows(
            UGP2 %>% mutate(genre = "Ultra Gaming"),
            MP2 %>% mutate(genre = "Magic Music EDM Gaming Playlist"),
            hip %>% mutate(genre = "Rap & Hip Hop Playlist 2021"),
            asP2 %>% mutate(genre = "Electronic Playlist 2020 "))
            


jazz3131 %>%
  mutate(
    sections =
      map(
        sections,                                    # sections or segments
        summarise_at,
        vars(tempo, loudness, duration),             # features of interest
        list(section_mean = mean, section_sd = sd)   # aggregation functions
      )
  ) %>%
  unnest(sections) %>%
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = genre,
      alpha = loudness
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_minimal() +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    colour = "Genre",
    size = "Duration (min)",
    alpha = "Volume (dBFS)"
  )
```

####


### Can we classify gaming music with **K nearest neighbor** classifier?

```{r cache=TRUE}

get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}  

LP5 <- 
  get_playlist_audio_features("spotify", "37i9dQZF1DWWEcRhUVtL8n")
GP5 <- get_playlist_audio_features("spotify", "37i9dQZF1DWTujiC7wfofZ")
UGP5 <- get_playlist_audio_features("spotify", "37i9dQZF1DXaRL7xbcDl7X")

hip <- get_playlist_audio_features("", "4fAWoOyXtEjLn9PT2RLyzO")
electronic <- get_playlist_audio_features("", "5CvETxDs2E5rQeNji0LPaA")


AI <-
  bind_rows(
    LP5 %>% mutate(playlist = "League of legends ") %>% slice_head(n = 20),
    GP5 %>% mutate(playlist = "Gaming") %>% slice_head(n = 20),
    electronic %>% mutate(playlist = "Electronic & dance") %>% slice_head(n = 20),
    hip %>% mutate(playlist = "Hiphop") %>% slice_head(n = 20),
  ) 



AI_features <-
  AI %>%  # For your portfolio, change this to the name of your corpus.
  add_audio_analysis() %>% 
  mutate(
    playlist = factor(playlist),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))


AI_recipe <-
  recipe(
    playlist ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = AI_features,          # Use the same name as the previous block.
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())      # Converts to z-scores.
  # step_range(all_predictors())    # Sets range to [0, 1].


AI_cv <- AI_features %>% vfold_cv(5)

knn_model <-
  nearest_neighbor(neighbors = 1) %>%
  set_mode("classification") %>% 
  set_engine("kknn")
AI_knn <- 
  workflow() %>% 
  add_recipe(AI_recipe) %>% 
  add_model(knn_model) %>% 
  fit_resamples(
    AI_cv, 
    control = control_resamples(save_pred = TRUE)
  )

```

```{r cache=TRUE}

abs <- AI_knn %>% get_conf_mat() %>% autoplot(type = "mosaic") + theme(axis.text.x = element_text(angle = 45, hjust = 1))

abc <- AI_knn %>% get_conf_mat() %>% autoplot(type = "heatmap") + theme(axis.text.x = element_text(angle = 45, hjust = 1))

subplot(abs,abc, margin = 0.1)
```

***
  
Here you can see a k nearest neighbor classifier trying to identify and classify each playlist after a 5-fold cross-validation. It is not particulairly accurate with it only preforming slightly better than 50/50. This might mean that it is very hard to differentiate the types of music in terms of features, thus meaning that they are very similair.

```{r cache=TRUE}
AI_knn %>% get_pr()
```




### What are the most important features to detect gaming music according to a random forest classifier?

```{r cache=TRUE, echo=FALSE}
forest_model <-
  rand_forest() %>%
  set_mode("classification") %>% 
  set_engine("ranger", importance = "impurity")
AI_forest <- 
  workflow() %>% 
  add_recipe(AI_recipe) %>% 
  add_model(forest_model) %>% 
  fit_resamples(
    AI_cv, 
    control = control_resamples(save_pred = TRUE)
  )

workflow() %>% 
  add_recipe(AI_recipe) %>% 
  add_model(forest_model) %>% 
  fit(AI_features) %>% 
  pluck("fit", "fit", "fit") %>%
  ranger::importance() %>% 
  enframe() %>% 
  mutate(name = fct_reorder(name, value)) %>% 
  ggplot(aes(name, value)) + 
  geom_col() + 
  coord_flip() +
  theme_minimal() +
  labs(x = NULL, y = "Importance")
```

***

We can see that the most important classifying features are **speechiness**, **c11** **c5** and **c6**. 
While it is not entirely know what the timbre coefficents mean, speechiness is a label that describes how much is spoken within a track. 
Can we use these features to identify gaming music? We could perhaps compare playlists using these features.



### Can the spotify **timbre coefficents** be used to identify gaming music?

####

Lets look into playlist wide **Timbre**. Timbre expresses the overall fidelity of a track. The random tree model revealed a substantial correlation between the playlists and the timbre coefficents c5, c6 and c11. To make a meaningfull comparison we will compare the Ultra gaming playlist, the Magic Music playlist, an [electronic playlist](https://open.spotify.com/playlist/5CvETxDs2E5rQeNji0LPaA?si=0fb6c3d6082f4863) and a [hiphop playlist](https://open.spotify.com/playlist/4fAWoOyXtEjLn9PT2RLyzO) 

---

Using Spotify's timbre analysis is the best option here. Spotify divides each track into 12 timbre coefficents, however the meaning and interpretation of these timbre coefficients is unclear. Futhermore within certain ranges of these coefficents the Gaming playlist contains outliers, thus only results between a range of 60 and -45 are used, this makes the plot more clear and removes the outlies which create a skewed image of the data.

####

```{r cache=TRUE}
MP2 <-
  get_playlist_audio_features("",
    "5AHH67GYsljwoB1q6UGvWg"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
UGP2 <-
  get_playlist_audio_features("",
    "37i9dQZF1DWYN9NBqvY7Tx"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
GP2 <-
  get_playlist_audio_features("",
    "2cjIvuw4VVOQSeUAZfNiqY"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
asP2 <-
  get_playlist_audio_features("",
    "1vXfh0fQrN5YQlhFVS6ec5"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
hip <-
  get_playlist_audio_features("",
    "4fAWoOyXtEjLn9PT2RLyzO"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
```


```{r cache=TRUE}
jazz1 <-
  bind_rows(
            UGP2 %>% mutate(genre = "Ultra Gaming"),
            MP2 %>% mutate(genre = "Magic Music EDM Gaming Playlist"))
jazz1 %>%
  mutate(
    timbre =
      map(
        segments,
        compmus_summarise,
        timbre,
        method = "mean"
      )
  ) %>%
  select(genre, timbre) %>%
  compmus_gather_timbre() %>%
  ggplot(aes(x = basis, y = value, fill = genre)) +
  geom_violin() +
  ylim(-45, 60) +
  scale_fill_viridis_d() +
  labs(x = "Spotify Timbre Coefficients", y = "", fill = "Genre", title="Gaming playlist comparison")

```

####

```{r cache=TRUE}

jazz2 <-
  bind_rows(
            UGP2 %>% mutate(genre = "Ultra Gaming"),
            asP2 %>% mutate(genre = "Electronic Playlist 2020 "))
jazz2 %>%
  mutate(
    timbre =
      map(
        segments,
        compmus_summarise,
        timbre,
        method = "mean"
      )
  ) %>%
  select(genre, timbre) %>%
  compmus_gather_timbre() %>%
  ggplot(aes(x = basis, y = value, fill = genre)) +
  geom_violin() +
  ylim(-45, 60) +
  scale_fill_viridis_d() +
  labs(x = "Spotify Timbre Coefficients", y = "", fill = "Genre", title="Gaming playlist electronic playlist comparison") +
  theme(plot.background = element_rect(fill = "transparent"))

```

####

```{r cache=TRUE}

jazz3 <-
  bind_rows(
            UGP2 %>% mutate(genre = "Ultra Gaming"),
            hip %>% mutate(genre = "Rap & Hip Hop Playlist 2021"))
jazz3 %>%
  mutate(
    timbre =
      map(
        segments,
        compmus_summarise,
        timbre,
        method = "mean"
      )
  ) %>%
  select(genre, timbre) %>%
  compmus_gather_timbre() %>%
  ggplot(aes(x = basis, y = value, fill = genre)) +
  geom_violin() +
  ylim(-45, 60) +
  scale_fill_viridis_d() +
  labs(x = "Spotify Timbre Coefficients", y = "", fill = "Genre", title="Gaming playlist Hiphop playlist comparison") +
  theme(plot.background = element_rect(fill = "transparent"))
```

***

Looking at the different playlist a difference is clearly visible at the coefficients c5 c6 and c11 this corresponds with the classifiers predictions.
So can we take a look at speechiness?


### Can **speechiness** be used to gaming music?

```{r cache=TRUE}

hip <- get_playlist_audio_features("", "4fAWoOyXtEjLn9PT2RLyzO")
electronic <- get_playlist_audio_features("", "5CvETxDs2E5rQeNji0LPaA")
XP014 <-
  bind_rows(
    LP %>% mutate(playlist = "League of legends"),
    GP %>% mutate(playlist = "Gaming"),
    MP %>% mutate(playlist = "Magic Music EDM Gaming"),
    UGP %>% mutate(playlist = "Ultra Gaming"),
    hip %>% mutate(playlist = "Rap & Hip Hop Playlist 2021"),
    electronic %>% mutate(playlist = "Electronic Playlist 2020")
  )


dasddadd <- XP014 %>% 
  ggplot(aes(x = speechiness, y=playlist ,fill= playlist)) +
  geom_boxplot()

ggplotly(dasddadd)


```

***

When looking at the speechiness attribute from spotify one cannot see the same direct similairity between gaming music as one can see when looking at the timbre coefficients. 


Conclusion
============

In conclusion we cannot differnetiate too well between gaming music and electronic music. However one can look at distinct properties when trying to descripte a piece of music made by riot games or other gaming music. Furthermre the range of what can been seen as gaming music is very large with both hiphop and electronic music blending in.
